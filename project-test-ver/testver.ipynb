{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from scipy.misc import imread, imsave\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLabModel(object):\n",
    "    \"\"\"\n",
    "    加载 DeepLab 模型；\n",
    "    推断 Inference.\n",
    "    \"\"\"\n",
    "    INPUT_TENSOR_NAME = 'ImageTensor:0'\n",
    "    OUTPUT_TENSOR_NAME = 'SemanticPredictions:0'\n",
    "    INPUT_SIZE = 513\n",
    "    FROZEN_GRAPH_NAME = 'frozen_inference_graph'\n",
    "\n",
    "    def __init__(self, tarball_path):\n",
    "        \"\"\"\n",
    "        加载预训练模型\n",
    "        \"\"\"\n",
    "        self.graph = tf.Graph()\n",
    "\n",
    "        graph_def = None\n",
    "        # Extract frozen graph from tar archive.\n",
    "        tar_file = tarfile.open(tarball_path)\n",
    "        for tar_info in tar_file.getmembers():\n",
    "            if self.FROZEN_GRAPH_NAME in os.path.basename(tar_info.name):\n",
    "                file_handle = tar_file.extractfile(tar_info)\n",
    "                graph_def = tf.GraphDef.FromString(file_handle.read())\n",
    "                break\n",
    "\n",
    "        tar_file.close()\n",
    "\n",
    "        if graph_def is None:\n",
    "            raise RuntimeError('Cannot find inference graph in tar archive.')\n",
    "\n",
    "        with self.graph.as_default():\n",
    "            tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "        self.sess = tf.Session(graph=self.graph)\n",
    "\n",
    "\n",
    "    def run(self, image):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "        image:  转换为PIL.Image 类,不能直接用图片，原始图片\n",
    "\n",
    "        Returns:\n",
    "        resized_image: RGB image resized from original input image.\n",
    "        seg_map: Segmentation map of `resized_image`.\n",
    "        \"\"\"\n",
    "        width, height = image.size\n",
    "        resize_ratio = 1.0 * self.INPUT_SIZE / max(width, height)\n",
    "        target_size = (int(resize_ratio * width), int(resize_ratio * height))\n",
    "        resized_image = image.convert('RGB').resize(target_size, Image.ANTIALIAS)\n",
    "        batch_seg_map = self.sess.run(self.OUTPUT_TENSOR_NAME,\n",
    "                                      feed_dict={self.INPUT_TENSOR_NAME: [np.asarray(resized_image)]})\n",
    "        seg_map = batch_seg_map[0]\n",
    "        return resized_image, seg_map\n",
    "\n",
    "    \n",
    "#===============================================================================================================\n",
    "def create_pascal_label_colormap():\n",
    "    colormap = np.zeros((256, 3), dtype=int)\n",
    "    ind = np.arange(256, dtype=int)\n",
    "\n",
    "    for shift in reversed(range(8)):\n",
    "        for channel in range(3):\n",
    "            colormap[:, channel] |= ((ind >> channel) & 1) << shift\n",
    "            ind >>= 3\n",
    "    return colormap\n",
    "\n",
    "def label_to_color_image(label):\n",
    "    if label.ndim != 2:\n",
    "        raise ValueError('Expect 2-D input label')\n",
    "\n",
    "    colormap = create_pascal_label_colormap()\n",
    "\n",
    "    if np.max(label) >= len(colormap):\n",
    "        raise ValueError('label value too large.')\n",
    "    return colormap[label]\n",
    "\n",
    "def load_model():\n",
    "    model_path = './deeplabmodels/deeplabv3_mnv2_pascal_train_aug_2018_01_29.tar.gz'#'deeplab_model.tar.gz'\n",
    "    MODEL = DeepLabModel(model_path)\n",
    "    #print('model loaded successfully!')\n",
    "    return MODEL\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class render():\n",
    "    def __init__(self, inputpic, modeldir = \"./models/cubist.model\", \n",
    "                 archdir = \"./models/model.meta\"):\n",
    "        self.input = inputpic\n",
    "        self.model = modeldir\n",
    "        self.arch = archdir\n",
    "\n",
    "        self.image = self.input.astype(np.float32)\n",
    "        self.image = np.expand_dims(self.image, axis = 0)\n",
    "\n",
    "\n",
    "    def run(self,session):\n",
    "\n",
    "        self.saver = tf.train.import_meta_graph(self.arch, clear_devices = True)\n",
    "        self.saver.restore(session, self.model)\n",
    "        self.inputs = tf.get_collection(\"inputs\")[0]\n",
    "        self.outputs = tf.get_collection(\"output\")[0]\n",
    "\n",
    "        self.time_s = time.time()\n",
    "        self.result = self.outputs.eval({self.inputs : self.image})\n",
    "        self.result = np.clip(self.result, 0.0, 255.0).astype(np.uint8)\n",
    "        self.result = np.squeeze(self.result, 0)\n",
    "        self.time_t = time.time()\n",
    "        print (\"First time. Time used: \", self.time_t - self.time_s)\n",
    "\n",
    "        self.time_s = time.time()\n",
    "        self.result = self.outputs.eval({self.inputs : self.image})\n",
    "        self.result = np.clip(self.result, 0.0, 255.0).astype(np.uint8)\n",
    "        self.result = np.squeeze(self.result, 0)\n",
    "        self.time_t = time.time()\n",
    "        print (\"Second time. Time used: \", self.time_t - self.time_s)\n",
    "\n",
    "        return self.result\n",
    "model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The saved meta_graph is possibly from an older release:\n",
      "'model_variables' collection should be of type 'byte_list', but instead is of type 'node_list'.\n",
      "WARNING:tensorflow:From D:\\ProgrammingAndSimulating\\Python\\anaconda3\\InstallPlace\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From D:\\ProgrammingAndSimulating\\Python\\anaconda3\\InstallPlace\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./models/cubist.model\n",
      "First time. Time used:  0.8921918869018555\n",
      "Second time. Time used:  0.04167318344116211\n",
      "Second time. Time used:  3.9635934829711914\n"
     ]
    }
   ],
   "source": [
    "time_1 = time.time()\n",
    "src = Image.open('./images/person3.jpg')\n",
    "resized_im, seg_map = model.run(src)\n",
    "seg_image = label_to_color_image(seg_map).astype(np.uint8)\n",
    "\n",
    "src = cv2.cvtColor(np.asarray(src),cv2.COLOR_RGB2BGR)\n",
    "resized_im = cv2.cvtColor(np.asarray(resized_im),cv2.COLOR_RGB2BGR)\n",
    "src_resized = cv2.resize(src,(resized_im.shape[1],resized_im.shape[0]))\n",
    "bg_img = np.zeros_like(src_resized)\n",
    "\n",
    "\n",
    "\n",
    "#============================================================================================\n",
    "tf.reset_default_graph()\n",
    "#title = \"composition_vii.model\"\n",
    "title = \"cubist.model\"\n",
    "#title = \"feathers.model\"\n",
    "#title = \"la_muse.model\"\n",
    "#title = \"mosaic.model\"\n",
    "#title = \"the_scream.model\"\n",
    "#title = \"udnie.model\"\n",
    "#title = \"wave.model\"\n",
    "class render():\n",
    "    def __init__(self, inputpic, modeldir = \"./models/\"+title, \n",
    "                 archdir = \"./models/model.meta\"):\n",
    "        self.input = inputpic\n",
    "        self.model = modeldir\n",
    "        self.arch = archdir\n",
    "\n",
    "        self.image = self.input.astype(np.float32)\n",
    "        self.image = np.expand_dims(self.image, axis = 0)\n",
    "\n",
    "\n",
    "    def run(self,session):\n",
    "\n",
    "        self.saver = tf.train.import_meta_graph(self.arch, clear_devices = True)\n",
    "        self.saver.restore(session, self.model)\n",
    "        self.inputs = tf.get_collection(\"inputs\")[0]\n",
    "        self.outputs = tf.get_collection(\"output\")[0]\n",
    "\n",
    "        self.time_s = time.time()\n",
    "        self.result = self.outputs.eval({self.inputs : self.image})\n",
    "        self.result = np.clip(self.result, 0.0, 255.0).astype(np.uint8)\n",
    "        self.result = np.squeeze(self.result, 0)\n",
    "        self.time_t = time.time()\n",
    "        print (\"First time. Time used: \", self.time_t - self.time_s)\n",
    "\n",
    "        self.time_s = time.time()\n",
    "        self.result = self.outputs.eval({self.inputs : self.image})\n",
    "        self.result = np.clip(self.result, 0.0, 255.0).astype(np.uint8)\n",
    "        self.result = np.squeeze(self.result, 0)\n",
    "        self.time_t = time.time()\n",
    "        print (\"Second time. Time used: \", self.time_t - self.time_s)\n",
    "\n",
    "        return self.result\n",
    "\n",
    "render_test = render(src_resized)\n",
    "\n",
    "session = tf.Session()\n",
    "with session.as_default():\n",
    "    styback = render_test.run(session)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "#=====================================================================\n",
    "result = np.zeros_like(src_resized)\n",
    "\n",
    "styback = Image.fromarray(styback.astype('uint8')).convert('RGB')\n",
    "styback = styback.resize((np.shape(result)[1],np.shape(result)[0]))\n",
    "styback = np.array(styback)\n",
    "\n",
    "result[seg_map > 0] = resized_im[seg_map > 0]\n",
    "result[seg_map == 0] = styback[seg_map == 0]\n",
    "\n",
    "\n",
    "time_2 = time.time()\n",
    "print (\"Second time. Time used: \", time_2 - time_1)\n",
    "\n",
    "\n",
    "cv2.imshow(title,result)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
